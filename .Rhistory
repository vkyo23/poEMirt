all(sort(x) == order(sort(x)))
}
) %>%
unlist() %>%
sum()
if (check != J) message('* WARNING: Some items have fewer response categories than your setting.')
# Converting into dataframe
d <- rep()
d
# 0. Setup -----
## Initialize workspace
rm(list = ls())
set.seed(1)
## Load packages
library(tidyverse)
# 1. Simulation -----
## Define sample size
I <- 200
J <- 400
T <- 40
maxK <- 5
## Timemaps
timemap <- matrix(1, I, T)
item_timemap <- rep(0:(T-1), each = J/T)
item_match <- rep(NA, J)
## Number of choice
if(maxK == 2) {
K <- rep(maxK, J)
} else {
K <- sample(2:maxK, J, replace = TRUE)
}
## Item parameters
alpha <- beta <- matrix(NA, J, maxK - 1)
for (j in 1:J) {
Kj <- K[j]
baseline_probs <- runif(Kj)
baseline_probs <- exp(baseline_probs)/sum(exp(baseline_probs))
baseline_sb <- cumprod(1-baseline_probs)/(1-baseline_probs) * baseline_probs
baseline_sb <- baseline_sb[1:(Kj-1)]
baseline_sb <- qlogis(baseline_sb)
x1_probs <- runif(Kj)
x1_probs <- exp(x1_probs)/sum(exp(x1_probs))
x1_sb <- cumprod(1-x1_probs)/(1-x1_probs) * x1_probs
x1_sb <- x1_sb[1:(Kj-1)]
x1_sb <- qlogis(x1_sb)
alpha[j, 1:(Kj-1)] <- baseline_sb
beta[j, 1:(Kj-1)] <- x1_sb - baseline_sb
}
# Latent traits
theta <- matrix(NA, I, T)
theta[, 1] <- rnorm(I)
for (t in 2:T) theta[, t] <- rnorm(I, theta[, t-1], 0.1)
con <- apply(theta, 2, which.max)
## Responses
Y <- array(NA, c(I, J, maxK))
n <- sample(500:1000, size = I * J, replace = TRUE) %>%
matrix(I, J)
#n <- matrix(1, I, J)
for (i in 1:I) {
for (j in 1:J) {
Kj <- K[j]
t <- item_timemap[j] + 1
if (Kj > 2) {
psi <- alpha[j, 1:(Kj-1)] + beta[j, 1:(Kj-1)] * theta[i, t]
psi <- plogis(psi)
p <- psi * c(1, cumprod(1 - psi))[-length(psi)]
p <- c(p, 1 - sum(p))
} else {
psi <- alpha[j, 1] + beta[j, 1] * theta[i, t]
psi <- plogis(psi)
p <- c(psi, 1 - psi)
}
Y[i, j, 1:Kj] <- rmultinom(1, n[i, j], p)
}
}
# Check
categories <- apply(colSums(Y, na.rm = TRUE), 1, function(x) which(x != 0), simplify = FALSE)
lapply(
categories,
function(x) {
all(sort(x) == order(sort(x)))
}
) %>%
unlist() %>%
sum()
# Converting into dataframe
d <- rep()
for (k in 1:maxK) {
if (k == 1) {
d <- Y[, , k] %>%
as_tibble() %>%
mutate(i = row_number()) %>%
pivot_longer(
cols = -i,
names_to = 'j',
values_to = paste0('y', k)
) %>%
mutate(
j = j %>%
str_remove('V') %>%
as.integer()
) %>%
bind_rows(d, .)
} else {
d <- Y[, , k] %>%
as_tibble() %>%
mutate(i = row_number()) %>%
pivot_longer(
cols = -i,
names_to = 'j',
values_to = paste0('y', k)
) %>%
select(-i, -j) %>%
bind_cols(d, .)
}
}
d <- d %>%
left_join(
tibble(
j = 1:J,
t = item_timemap + 1
),
by = 'j'
) %>%
relocate(t, .before = y1) %>%
arrange(j)
d
tail(d)
head(d)
sim_data_dynamic <- d
saveRDS(sim_data_dynamic, file = 'data/sim_data_dynamic.rds')
# 0. Setup -----
## Initialize workspace
rm(list = ls())
set.seed(1)
## Load packages and function
library(tidyverse)
# 1. Simulation -----
## Define sample size
I <- 500
J <- 100
maxK <- 5
## Number of choice
K <- sample(2:maxK, J, replace = TRUE)
#K <- rep(maxK, J)
## Item parameters
alpha <- beta <- matrix(NA, J, maxK - 1)
for (j in 1:J) {
Kj <- K[j]
baseline_probs <- runif(Kj)
baseline_probs <- exp(baseline_probs)/sum(exp(baseline_probs))
baseline_sb <- cumprod(1-baseline_probs)/(1-baseline_probs) * baseline_probs
baseline_sb <- baseline_sb[1:(Kj-1)]
baseline_sb <- qlogis(baseline_sb)
x1_probs <- runif(Kj)
x1_probs <- exp(x1_probs)/sum(exp(x1_probs))
x1_sb <- cumprod(1-x1_probs)/(1-x1_probs) * x1_probs
x1_sb <- x1_sb[1:(Kj-1)]
x1_sb <- qlogis(x1_sb)
alpha[j, 1:(Kj-1)] <- baseline_sb
beta[j, 1:(Kj-1)] <- x1_sb - baseline_sb
}
# Latent traits
theta <- rnorm(I)
con <- which.max(theta)
theta[con]
## Responses
Y <- array(NA, c(I, J, maxK))
n <- sample(500:100, size = I * J, replace = TRUE) %>%
matrix(I, J)
#n <- matrix(1, I, J)
for (i in 1:I) {
for (j in 1:J) {
Kj <- K[j]
if (Kj > 2) {
psi <- alpha[j, 1:(Kj-1)] + beta[j, 1:(Kj-1)] * theta[i]
psi <- plogis(psi)
p <- psi * c(1, cumprod(1 - psi))[-length(psi)]
p <- c(p, 1 - sum(p))
} else {
psi <- alpha[j, 1] + beta[j, 1] * theta[i]
psi <- plogis(psi)
p <- c(psi, 1 - psi)
}
Y[i, j, 1:Kj] <- rmultinom(1, n[i, j], p)
}
}
categories <- apply(colSums(Y, na.rm = TRUE), 1, function(x) which(x != 0), simplify = FALSE)
lapply(
categories,
function(x) {
all(sort(x) == order(sort(x)))
}
) %>%
unlist()
d <- rep()
for (k in 1:maxK) {
if (k == 1) {
d <- Y[, , k] %>%
as_tibble() %>%
mutate(i = row_number()) %>%
pivot_longer(
cols = -i,
names_to = 'j',
values_to = paste0('y', k)
) %>%
mutate(
j = j %>%
str_remove('V') %>%
as.integer()
) %>%
bind_rows(d, .)
} else {
d <- Y[, , k] %>%
as_tibble() %>%
mutate(i = row_number()) %>%
pivot_longer(
cols = -i,
names_to = 'j',
values_to = paste0('y', k)
) %>%
select(-i, -j) %>%
bind_cols(d, .)
}
}
sim_data_static <- d
saveRDS(sim_data_static, file = 'data/sim_data_static.rds')
readRDS('data/sim_data_dynamic.rds')
usethis::use_readme_rmd()
devtools::load_all()
data("sim_data_dynamic")
devtools::document()
devtools::document()
devtools::document()
sim_data_dynamic <- readRDS('data/sim_data_dynamic.rds')
save(sim_data_dynamic, file = 'data/sim_data_dynamic.rda')
laod('data/sim_data_dynamic.rda')
load('data/sim_data_dynamic.rda')
sim_data_static <- readRDS('data/sim_data_static.rds')
save(sim_data_static, file = 'data/sim_data_static.rda')
rm(list=ls())
load('data/sim_data_static.rda')
View(sim_data_static)
devtools::document()
devtools::check()
devtools::load_all()
data("sim_data_dynamic")
data("sim_data_dynamic")
head(sim_data_dynamic)
tail(sim_data_dynamic)
# Convert into poEMirt-readable data
data <- read_poEMirt(
data = sim_data_dynamic,
i = "i",
j = "j",
t = "t"
)
paste0('y', 1:5)
# Convert into poEMirt-readable data
data <- read_poEMirt(
data = sim_data_dynamic,
responses = paste0('y', 1:5),
i = "i",
j = "j",
t = "t"
)
# Fit the model
fit <- poEMirt(
data = data,
model = 'dynamic',
control = list(
verbose = 10
)
)
# Fit the model
fit <- poEMirt(
data = data,
model = 'dynamic',
control = list(
verbose = 10,
constrant = 1
)
)
data = data
model = 'dynamic'
control = list(
verbose = 10,
constrant = 1
)
# alpha and beta
alpha_init <- beta_init <- matrix(0, data$size$J, data$size$maxK-1)
sums <- colSums(data$response, na.rm = TRUE)
for (j in 1:data$size$J) {
Kj <- max(data$categories[[j]])
prob <- sums[j, ] / sum(sums[j, ])
prob <- prob[prob != 0]
running <- cumsum(prob) / sum(prob)
sb <- prob / (1 - (running - prob))
sb <- sb[1:(Kj-1)]
alpha_init[j, 1:(Kj-1)] <- stats::qlogis(sb)
beta_init[j, 1:(Kj-1)] <- 0.1
}
# theta
Yimp <- data$response[, , 1] / data$trial
Yimp <- apply(Yimp, 2, med_impute)
theta_init <- scale(stats::prcomp(Yimp)$x[, 1])
theta_init
constraint <- which.max(theta_init)
constraint <- rep(which.max(theta_init), data$size$T)
devtools::load_all()
data("sim_data_dynamic")
head(sim_data_dynamic)
tail(sim_data_dynamic)
# Convert into poEMirt-readable data
data <- read_poEMirt(
data = sim_data_dynamic,
responses = paste0('y', 1:5),
i = "i",
j = "j",
t = "t"
)
# Fit the model
fit <- poEMirt(
data = data,
model = 'dynamic',
control = list(
verbose = 10,
constrant = 1
)
)
# Summarize the result
summary(fit)
# Summarize the result
summary(fit, parameter = "theta")
fit_boot <- poEMirt_uncertainty(
fit = fit,
method = "bootstrap",
seed = 1,
iter = 100,
control = list(
verbose = 10
)
)
devtools::load_all()
''
devtools::load_all()
data("sim_data_dynamic")
head(sim_data_dynamic)
# Convert into poEMirt-readable data
data <- read_poEMirt(
data = sim_data_dynamic,
responses = paste0('y', 1:5),
i = "i",
j = "j",
t = "t"
)
# Fit the model
fit <- poEMirt(
data = data,
model = "dynamic",
control = list(
verbose = 10,
constrant = 1
)
)
# Summarize the result
summary(fit, parameter = "theta")
fit_boot <- poEMirt_uncertainty(
fit = fit,
method = "bootstrap",
seed = 1,
iter = 100,
control = list(
verbose = 10
)
)
summary(fit_boot, parameter = "theta")
?as_tibble.matrix
I=100
J=100
maxK=3
nrange=1
# Number of choice
if(maxK == 2) {
K <- rep(maxK, J)
} else {
K <- sample(2:maxK, J, replace = TRUE)
}
# Item parameters
alpha <- beta <- matrix(NA, J, maxK - 1)
for (j in 1:J) {
Kj <- K[j]
baseline_probs <- runif(Kj)
baseline_probs <- exp(baseline_probs)/sum(exp(baseline_probs))
baseline_sb <- cumprod(1-baseline_probs)/(1-baseline_probs) * baseline_probs
baseline_sb <- baseline_sb[1:(Kj-1)]
baseline_sb <- stats::qlogis(baseline_sb)
x1_probs <- stats::runif(Kj)
x1_probs <- exp(x1_probs)/sum(exp(x1_probs))
x1_sb <- cumprod(1-x1_probs)/(1-x1_probs) * x1_probs
x1_sb <- x1_sb[1:(Kj-1)]
x1_sb <- stats::qlogis(x1_sb)
alpha[j, 1:(Kj-1)] <- baseline_sb
beta[j, 1:(Kj-1)] <- x1_sb - baseline_sb
}
if (!is.null(T)) {
# Latent traits
theta <- matrix(NA, I, T)
theta[, 1] <- stats::rnorm(I)
for (t in 2:T) theta[, t] <- stats::rnorm(I, theta[, t-1], 0.1)
con <- apply(theta, 2, which.max)
} else {
theta <- stats::rnorm(I)
con <- which.max(theta)
}
## Responses
if (length(n_range) == 1) {
n <- matrix(n_range, I, J)
} else {
n <- sample(n_range[1]:n_range[2], size = I * J, replace = TRUE) %>%
matrix(I, J)
}
theta <- stats::rnorm(I)
con <- which.max(theta)
## Responses
if (length(n_range) == 1) {
n <- matrix(n_range, I, J)
} else {
n <- sample(n_range[1]:n_range[2], size = I * J, replace = TRUE) %>%
matrix(I, J)
}
n_range=1
n <- matrix(n_range, I, J)
Y <- array(NA, c(I, J, maxK))
for (i in 1:I) {
for (j in 1:J) {
Kj <- K[j]
if (!is.null(T)) t <- item_timemap[j] + 1
if (Kj > 2) {
if (!is.null(T)) {
psi <- alpha[j, 1:(Kj-1)] + beta[j, 1:(Kj-1)] * theta[i, t]
} else {
psi <- alpha[j, 1:(Kj-1)] + beta[j, 1:(Kj-1)] * theta[i]
}
psi <- stats::plogis(psi)
p <- psi * c(1, cumprod(1 - psi))[-length(psi)]
p <- c(p, 1 - sum(p))
} else {
if (!is.null(T)) {
psi <- alpha[j, 1] + beta[j, 1] * theta[i, t]
} else {
psi <- alpha[j, 1] + beta[j, 1] * theta[i]
}
psi <- stats::plogis(psi)
p <- c(psi, 1 - psi)
}
Y[i, j, 1:Kj] <- stats::rmultinom(1, n[i, j], p)
}
}
T=NULL
Y <- array(NA, c(I, J, maxK))
for (i in 1:I) {
for (j in 1:J) {
Kj <- K[j]
if (!is.null(T)) t <- item_timemap[j] + 1
if (Kj > 2) {
if (!is.null(T)) {
psi <- alpha[j, 1:(Kj-1)] + beta[j, 1:(Kj-1)] * theta[i, t]
} else {
psi <- alpha[j, 1:(Kj-1)] + beta[j, 1:(Kj-1)] * theta[i]
}
psi <- stats::plogis(psi)
p <- psi * c(1, cumprod(1 - psi))[-length(psi)]
p <- c(p, 1 - sum(p))
} else {
if (!is.null(T)) {
psi <- alpha[j, 1] + beta[j, 1] * theta[i, t]
} else {
psi <- alpha[j, 1] + beta[j, 1] * theta[i]
}
psi <- stats::plogis(psi)
p <- c(psi, 1 - psi)
}
Y[i, j, 1:Kj] <- stats::rmultinom(1, n[i, j], p)
}
}
# Check
categories <- apply(colSums(Y, na.rm = TRUE), 1, function(x) which(x != 0), simplify = FALSE)
check <- lapply(
categories,
function(x) {
all(sort(x) == order(sort(x)))
}
) %>%
unlist() %>%
sum()
if (check != J) message('* WARNING: Some items have fewer response categories than your setting.')
Y[, , k] %>%
dplyr::as_tibble()
k=1
Y[, , k] %>%
dplyr::as_tibble()
Y[, , k] %>%
dplyr::as_tibble(.name_repair = 'minimal')
Y[, , k] %>%
dplyr::as_tibble(.name_repair = 'unique')
Y[, , k] %>%
dplyr::as_tibble(.name_repair = 'check_unique')
Y[, , k] %>%
dplyr::as_tibble() %>%
suppressWarnings()
devtools::load_all()
